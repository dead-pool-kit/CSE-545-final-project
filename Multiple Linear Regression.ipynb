{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Multiple Linear Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["{'_Cost_of_business_startup_procedures_percent_of_GNI_per_capita': {'_Hightechnology_exports_current_USD': 0.06279483562401837,\n","  '_New_business_density_new_registrations_per_1000_people_ages_1564': 0.142573901668899,\n","  '_Mineral_rents_percent_of_GDP': 0.6844710558842995,\n","  '_Research_and_development_expenditure_percent_of_GDP': 0.045585112899943325,\n","  '_Net_bilateral_aid_flows_from_DAC_donors_Total_current_USD': 0.012552253513837302\n","  'f_vaue': 29908067.879596103,\n","  'p_value': 0.00014399058911584832},\n"," \n"," '_International_tourism_expenditures_percent_of_total_imports': {'_Forest_area_percent_of_land_area': -0.008552660115673271,\n","  '_GNI_current_USD': 0.004317885894742004,\n","  '_Merchandise_trade_percent_of_GDP': -0.022741687999705745,\n","  'f_vaue': 51690608.66154766,\n","  'p_value': 0.00010952732108288012},\n"," \n"," '_Military_expenditure_percent_of_GDP': {'_Automated_teller_machines_ATMs_per_100000_adults': -0.0040696222312887635,\n","  '_PM25_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_percent_of_total': -0.005482464040256872,\n","  '_Physicians_per_1000_people': 0.004063511369047278,\n","  'f_vaue': 27522110.78867388,\n","  'p_value': 0.00015010232449026213},\n"," \n"," '_Research_and_development_expenditure_percent_of_GDP': {'_Forest_rents_percent_of_GDP': 0.002911994446159387,\n","  '_Import_value_index_2000__100': -0.0015912541928805202,\n","  '_Trade_percent_of_GDP': 0.0015318687296084939,\n","  'f_vaue': 26742358.771285325,\n","  'p_value': 0.00015227493809608035}}"],"metadata":{"id":"xd6gyGXjrj1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["{'_Cost_of_business_startup_procedures_percent_of_GNI_per_capita': {'_Adjusted_savings_energy_depletion_percent_of_GNI': -0.15036660951976968,\n","  '_Energy_intensity_level_of_primary_energy_MJD2011_PPP_GDP': 0.142573901668899,\n","  '_Research_and_development_expenditure_percent_of_GDP': -0.5266038396121484,\n","  'f_vaue': 29908067.879596103,\n","  'p_value': 0.00014399058911584832},\n"," '_International_tourism_expenditures_percent_of_total_imports': {'_Forest_area_percent_of_land_area': -0.008552660115673271,\n","  '_GNI_current_USD': 0.004317885894742004,\n","  '_Merchandise_trade_percent_of_GDP': -0.022741687999705745,\n","  'f_vaue': 51690608.66154766,\n","  'p_value': 0.00010952732108288012},\n"," '_Military_expenditure_percent_of_GDP': {'_Automated_teller_machines_ATMs_per_100000_adults': -0.0040696222312887635,\n","  '_PM25_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_percent_of_total': -0.005482464040256872,\n","  '_Physicians_per_1000_people': 0.004063511369047278,\n","  'f_vaue': 27522110.78867388,\n","  'p_value': 0.00015010232449026213},\n"," '_Research_and_development_expenditure_percent_of_GDP': {'_Forest_rents_percent_of_GDP': 0.002911994446159387,\n","  '_Import_value_index_2000__100': -0.0015912541928805202,\n","  '_Trade_percent_of_GDP': 0.0015318687296084939,\n","  'f_vaue': 26742358.771285325,\n","  'p_value': 0.00015227493809608035}}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZzR9a6PoZyS","executionInfo":{"status":"ok","timestamp":1652683813054,"user_tz":240,"elapsed":158,"user":{"displayName":"Pratik Thorwe","userId":"08079398622802778737"}},"outputId":"bc740467-0b03-4286-db85-a05225b9764f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_Cost_of_business_startup_procedures_percent_of_GNI_per_capita': {'_Adjusted_savings_energy_depletion_percent_of_GNI': -0.15036660951976968,\n","  '_Energy_intensity_level_of_primary_energy_MJD2011_PPP_GDP': 0.142573901668899,\n","  '_Research_and_development_expenditure_percent_of_GDP': -0.5266038396121484,\n","  'f_vaue': 29908067.879596103,\n","  'p_value': 0.00014399058911584832},\n"," '_International_tourism_expenditures_percent_of_total_imports': {'_Forest_area_percent_of_land_area': -0.008552660115673271,\n","  '_GNI_current_USD': 0.004317885894742004,\n","  '_Merchandise_trade_percent_of_GDP': -0.022741687999705745,\n","  'f_vaue': 51690608.66154766,\n","  'p_value': 0.00010952732108288012},\n"," '_Military_expenditure_percent_of_GDP': {'_Automated_teller_machines_ATMs_per_100000_adults': -0.0040696222312887635,\n","  '_PM25_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_percent_of_total': -0.005482464040256872,\n","  '_Physicians_per_1000_people': 0.004063511369047278,\n","  'f_vaue': 27522110.78867388,\n","  'p_value': 0.00015010232449026213},\n"," '_Research_and_development_expenditure_percent_of_GDP': {'_Forest_rents_percent_of_GDP': 0.002911994446159387,\n","  '_Import_value_index_2000__100': -0.0015912541928805202,\n","  '_Trade_percent_of_GDP': 0.0015318687296084939,\n","  'f_vaue': 26742358.771285325,\n","  'p_value': 0.00015227493809608035}}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["################################# Final Dictionary ############################\n","\n","{'_Cost_of_business_startup_procedures_percent_of_GNI_per_capita': {'_GNI_current_USD': 1.0773676660013456e-08,\n","  '_Listed_domestic_companies_total': 6.753632008268942e-09,\n","  '_Net_bilateral_aid_flows_from_DAC_donors_Germany_current_USD': -1.1357059606418142e-08,\n","  'f_vaue': 29908067.879596103,\n","  'p_value': 0.00014399058911584832},\n"," '_International_tourism_expenditures_percent_of_total_imports': {'_GDP_per_capita_PPP_current_international_D': -1.8162863503391458e-10,\n","  '_International_tourism_number_of_arrivals': 1.7690636085491376e-10,\n","  '_New_business_density_new_registrations_per_1000_people_ages_1564': 2.214024856643264e-10,\n","  'f_vaue': 51690608.66154766,\n","  'p_value': 0.00010952732108288012},\n"," '_Military_expenditure_percent_of_GDP': {'_CO2_emissions_metric_tons_per_capita': -1.2972260021284721e-10,\n","  '_Foreign_direct_investment_net_outflows_BoP_current_USD': 1.7919210452775533e-12,\n","  '_New_business_density_new_registrations_per_1000_people_ages_1564': 1.2818774075586375e-10,\n","  'f_vaue': 27522110.78867388,\n","  'p_value': 0.00015010232449026213},\n"," '_Research_and_development_expenditure_percent_of_GDP': {'_CO2_emissions_metric_tons_per_capita': -2.134749879221047e-11,\n","  '_Exports_as_a_capacity_to_import_constant_LCU': -1.8662144149712564e-10,\n","  '_Foreign_direct_investment_net_outflows_BoP_current_USD': 3.3715784699329417e-13,\n","  'f_vaue': 26742358.771285325,\n","  'p_value': 0.00015227493809608035}}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrKdnuVqkKxK","executionInfo":{"status":"ok","timestamp":1652682701671,"user_tz":240,"elapsed":177,"user":{"displayName":"Pratik Thorwe","userId":"08079398622802778737"}},"outputId":"4de08a49-8dd8-4514-d986-b8095d54c329"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_Cost_of_business_startup_procedures_percent_of_GNI_per_capita': {'_GNI_current_USD': 1.0773676660013456e-08,\n","  '_Listed_domestic_companies_total': 6.753632008268942e-09,\n","  '_Net_bilateral_aid_flows_from_DAC_donors_Germany_current_USD': -1.1357059606418142e-08,\n","  'f_vaue': 29908067.879596103,\n","  'p_value': 0.00014399058911584832},\n"," '_International_tourism_expenditures_percent_of_total_imports': {'_GDP_per_capita_PPP_current_international_D': -1.8162863503391458e-10,\n","  '_International_tourism_number_of_arrivals': 1.7690636085491376e-10,\n","  '_New_business_density_new_registrations_per_1000_people_ages_1564': 2.214024856643264e-10,\n","  'f_vaue': 51690608.66154766,\n","  'p_value': 0.00010952732108288012},\n"," '_Military_expenditure_percent_of_GDP': {'_CO2_emissions_metric_tons_per_capita': -1.2972260021284721e-10,\n","  '_Foreign_direct_investment_net_outflows_BoP_current_USD': 1.7919210452775533e-12,\n","  '_New_business_density_new_registrations_per_1000_people_ages_1564': 1.2818774075586375e-10,\n","  'f_vaue': 27522110.78867388,\n","  'p_value': 0.00015010232449026213},\n"," '_Research_and_development_expenditure_percent_of_GDP': {'_CO2_emissions_metric_tons_per_capita': -2.134749879221047e-11,\n","  '_Exports_as_a_capacity_to_import_constant_LCU': -1.8662144149712564e-10,\n","  '_Foreign_direct_investment_net_outflows_BoP_current_USD': 3.3715784699329417e-13,\n","  'f_vaue': 26742358.771285325,\n","  'p_value': 0.00015227493809608035}}"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["{'_GDP_current_USD': {'_Exports_as_a_capacity_to_import_constant_LCU': 0.03643190474332815,\n","  '_Exports_of_goods_and_services_percent_of_GDP': 0.013174394848275442,\n","  '_Trade_percent_of_GDP': 0.4536792705366437,\n","  'f_value': 396.036402264229,\n","  'p_value': 0.0005\n","  }}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObB3jE9f3hp-","executionInfo":{"status":"ok","timestamp":1652671215756,"user_tz":240,"elapsed":178,"user":{"displayName":"Pratik Thorwe","userId":"08079398622802778737"}},"outputId":"cf8ce72c-dd93-4b62-f6ae-7f54b766bae3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_GDP_current_USD': {'_Exports_as_a_capacity_to_import_constant_LCU': 0.03643190474332815,\n","  '_Exports_of_goods_and_services_percent_of_GDP': 0.013174394848275442,\n","  '_Trade_percent_of_GDP': 0.4536792705366437,\n","  'f_value': 396.036402264229,\n","  'p_value': 0.0005}}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["{'_Urban population percent_of_total_population': {' \"Access to electricity urban (% of urban population)\"': -0.9311303201796531,\n","  ' \"Energy intensity level of primary energy (MJ/$2011 PPP GDP)\"': -2.803055167966104e-09,\n","  ' \"Net bilateral aid flows from DAC donors United States (current US$)\"': 29.93945459153294,\n","  'f_value': 396.036402264229,\n","  'p_value': 5.983446871689151e-229}}"],"metadata":{"id":"BLaaUcmN1eMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res2 = test_hypothesis('Urban_population_percent_of_total_population', ['Listed_domestic_companies_total', 'Net_bilateral_aid_flows_from_DAC_donors_United_States_current_USD', 'Energy_intensity_level_of_primary_energy_MJD2011_PPP_GDP', 'Access_to_electricity_urban_percent_of_urban_population'], 'India')\n","    "],"metadata":{"id":"rfIRUedsszvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_intersection(stats):\n","    target_countries = set(['India', 'China', 'United States', 'Australia', 'Brazil', 'Canada', 'France', \n","                            'Germany', 'Israel', 'Japan', 'South Africa', 'Korea, Rep.', \n","                            'Mexico', 'New Zealand', 'Netherlands', 'Pakistan', 'Portugal', \n","                            'Russian Federation', 'Singapore', 'Spain', 'Thailand', 'United Kingdom', 'Vietnam'])\n","\n","    related_attributes = set(dict(stats[0][1][3]))\n","    for country, value in stats[1:]:\n","        if country in target_countries:\n","            attributes = dict(value[3])\n","            related_attributes = related_attributes & attributes\n","            # stats[0][1][3] = \n","\n","    return related_attributes\n","\n","def data_sanitisation():\n","    global dataMainCountries\n","\n","    df = dataMainCountries.copy(deep=True)\n","    df.fillna(0, inplace=True)\n","    original_dict = {}\n","\n","    col = list(df.columns)\n","    # index_dictionary = {}\n","    replace_dict = {'%': 'percent', '(': '', ')': '', ',': '', ':': '', '-': '', '$': 'D', '.': '', '/': '', '=': '', '&': '', ' ': '_', '\"': ''}\n","\n","\n","\n","    for i, attribute in enumerate(col):\n","        original = attribute\n","        for key in replace_dict:\n","            attribute = attribute.replace(key, replace_dict[key])\n","        col[i] = attribute\n","        original_dict[attribute] = original\n","    return df, col, original_dict\n"],"metadata":{"id":"tC8I8jBassPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def null_hypothesis_rejected(fvalue, f_pvalue):\n","    return fvalue > 1 and f_pvalue < 0.05\n","\n","\n","def compute_formula(target_attribute, other_attributes):\n","    formula = str(target_attribute) + \" ~ \"\n","\n","    for i, attribute in enumerate(other_attributes):\n","        # print(attribute)\n","        if attribute != target_attribute:\n","            formula += str(other_attributes[i]) + \" + \"\n","\n","    formula = formula[:-3]\n","    # print(formula)\n","    return formula\n","\n","\n","def compute_dependency(dataframe, target_attribute, other_attributes):\n","    fvalue, f_pvalue = 0, 0\n","\n","    #while not null_hypothesis_rejected(fvalue, f_pvalue):\n","    #for i in range(30):\n","    col = list(dataframe.columns)\n","    formula = compute_formula(target_attribute, other_attributes)\n","    # print('-----------------------------------------------------------------------')\n","    # print('formula')\n","    # print(formula)\n","    # print(col)\n","    # print('-----------------------------------------------------------------------')\n","    if target_attribute in col: \n","        col.remove(target_attribute)\n","    \n","    try:\n","        model = smf.ols(formula = formula, data = dataframe)\n","\n","    except:\n","        # print('formula: ', formula)\n","        # print('target: ', target_attribute)\n","        # print('dataframe: ', dataframe)\n","        return 0, 0, []\n","\n","        \n","    result = model.fit()\n","    fvalue = result.fvalue\n","    f_pvalue = result.f_pvalue\n","    params = list(result.params)\n","    mapped_params = [(col[i], params[i]) for i in range(min(len(params), len(col)))]\n","    sorted_params = sorted(mapped_params, key = lambda x: abs(x[1]))\n","    least_imp_param = sorted_params[0][0]\n","    dataframe.drop(least_imp_param, inplace=True, axis=1)\n","\n","    if len(sorted_params) < 3:\n","        return fvalue, f_pvalue, len(sorted_params), sorted_params\n","\n","    # print(params)\n","\n","    return fvalue, f_pvalue, sorted_params # result\n","\n","\n","def remaping(stats, originals):\n","    print(stats)\n","    for j, attribute in enumerate(stats[2]):\n","        stats[2][j] = (originals[stats[2][j][0]], stats[2][j][1])\n","    return stats\n","\n","\n","\n","def sanitised(col):\n","    originals = {}\n","    replace_dict = {'%': 'percent', '(': '', ')': '', ',': '', ':': '', '-': '', '$': 'D', '.': '', '/': '', '=': '', '&': '', ' ': '_', '\"': ''}\n","\n","    for i, attribute in enumerate(col):\n","        original = attribute\n","        for key in replace_dict:\n","            attribute = attribute.replace(key, replace_dict[key])\n","        col[i] = attribute\n","        originals[attribute] = original\n","\n","        return col[0], col[1:], originals\n","\n","\n","############################################### Use This Function ########################################\n","def test_hypothesis(target_attribute, dependent_attributes, country):\n","    df, col, original_dict = data_sanitisation()\n","    # print(df.columns)\n","    # print(col)\n","\n","    df.columns = col\n","    target_attribute, dependent_attributes, originals = sanitised([target_attribute] + dependent_attributes)\n","    \n","    # df.drop(columns = ['Country_Name', '_Country_Code', '_Year'], inplace = True, axis = 1)\n","    # new_df = df.filter(items = [target_attribute] + dependent_attributes, axis = 1)\n","    # print('-----------------------------------------------------------------------')\n","    # print(target_attribute)\n","    # print(dependent_attributes)\n","    # print(country)\n","    # print(df.columns)\n","    # # print(new_df)\n","    # print('-----------------------------------------------------------------------')\n","    res = compute_dependency(df, target_attribute, dependent_attributes)\n","    ############### Code to group by country ##############\n","    # file_rdd = sc.parallelize(df.to_numpy())\n","\n","    # grouped_rdd = file_rdd.map(lambda x: (x[0], x[3:])).groupByKey().mapValues(list)\n","\n","    # df_rdd = grouped_rdd.map(lambda x: (x[0], pd.DataFrame(x[1], columns = col[3:]) ))       # Grouping Country wise and dropping country code and time fields\n","    \n","    # model_rdd = df_rdd.map(lambda x: (x[0], compute_dependency(x[1], target_attribute))) #.map(lambda x: (x[0], x[1].params))\n","\n","    \n","    # # summary_rdd = model_rdd.map(lambda x: (x[0], x[1].fvalue, x[1].f_pvalue))\n","    # stats = model_rdd.collectAsMap()\n","\n","    # res = stats[country]\n","\n","    new_stats = remaping(res, original_dict)\n","    # print(model_rdd.collect())\n","    return new_stats"],"metadata":{"id":"JWqch5ySrnfg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["############################################### Copy everything below this in this cell #####################################\n","\n","def sanitised(col):\n","    originals = {}\n","    replace_dict = {'%': 'percent', '(': '', ')': '', ',': '', ':': '', '-': '', '$': 'D', '.': '', '/': '', '=': '', '&': '', ' ': '_', '\"': ''}\n","\n","    for i, attribute in enumerate(col):\n","        original = attribute\n","        for key in replace_dict:\n","            attribute = attribute.replace(key, replace_dict[key])\n","        col[i] = attribute\n","        originals[attribute] = original\n","\n","        return col[0], col[1:], originals\n","\n","\n","############################################### Use This Function ########################################\n","def test_hypothesis(target_attribute, dependent_attributes, country):\n","    df, col, original_dict = data_sanitisation()\n","    # print(df.columns)\n","    # print(col)\n","    df.columns = col\n","    target_attribute, dependent_attributes, originals = sanitised([target_attribute] + dependent_attributes)\n","    \n","    # df.drop(columns = ['Country_Name', '_Country_Code', '_Year'], inplace = True, axis = 1)\n","    new_df = df.filter([target_attribute] + dependent_attributes, axis = 1)\n","    # print(new_df.columns)\n","    res = compute_dependency(new_df, target_attribute)\n","    ############### Code to group by country ##############\n","    # file_rdd = sc.parallelize(df.to_numpy())\n","\n","    # grouped_rdd = file_rdd.map(lambda x: (x[0], x[3:])).groupByKey().mapValues(list)\n","\n","    # df_rdd = grouped_rdd.map(lambda x: (x[0], pd.DataFrame(x[1], columns = col[3:]) ))       # Grouping Country wise and dropping country code and time fields\n","    \n","    # model_rdd = df_rdd.map(lambda x: (x[0], compute_dependency(x[1], target_attribute))) #.map(lambda x: (x[0], x[1].params))\n","\n","    \n","    # # summary_rdd = model_rdd.map(lambda x: (x[0], x[1].fvalue, x[1].f_pvalue))\n","    # stats = model_rdd.collectAsMap()\n","\n","    # res = stats[country]\n","\n","    new_stats = remaping(res, original_dict)\n","    # print(model_rdd.collect())\n","    return new_stats\n","\n","\n","new_stats = test_hypothesis('_Urban population percent_of_total_population', ['_Listed domestic companies total', '_Net_bilateral_aid_flows_from_DAC_donors_United_States_current_USD', '_Energy_intensity_level_of_primary_energy_MJD2011_PPP_GDP', '_Access_to_electricity_urban_percent_of_urban_population'], 'India')"],"metadata":{"id":"LJqaXGc5b6kA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dict(zip(df.state, df.name))\n","new_stats = test_hypothesis('_Urban_population_percent_of_total_population', ['_Listed_domestic_companies_total', '_Net_bilateral_aid_flows_from_DAC_donors_United_States_current_USD', '_Energy_intensity_level_of_primary_energy_MJD2011_PPP_GDP', '_Access_to_electricity_urban_percent_of_urban_population'], 'India')\n","\n","\n","coeff_dict = dict(new_stats[2])\n","coeff_dict['f_value'] = new_stats[0]\n","coeff_dict['p_value'] = new_stats[1]\n","json_obj = json.dumps(coeff_dict)\n","\n","import pyspark\n","from pyspark.sql import SparkSession\n","import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","from collections import defaultdict\n","\n","sc = pyspark.SparkContext()\n","\n","def find_intersection(stats):\n","    target_countries = set(['India', 'China', 'United States', 'Australia', 'Brazil', 'Canada', 'France', \n","                            'Germany', 'Israel', 'Japan', 'South Africa', 'Korea, Rep.', \n","                            'Mexico', 'New Zealand', 'Netherlands', 'Pakistan', 'Portugal', \n","                            'Russian Federation', 'Singapore', 'Spain', 'Thailand', 'United Kingdom', 'Vietnam'])\n","\n","    related_attributes = set(dict(stats[0][1][3]))\n","    for country, value in stats[1:]:\n","        if country in target_countries:\n","            attributes = dict(value[3])\n","            related_attributes = related_attributes & attributes\n","            # stats[0][1][3] = \n","\n","    return related_attributes\n","\n","def data_sanitisation():\n","    df = pd.read_csv('/content/drive/MyDrive/dfCountryImputed2.csv')\n","    df.fillna(0, inplace=True)\n","    original_dict = {}\n","\n","    col = list(df.columns)\n","    # index_dictionary = {}\n","    replace_dict = {'%': 'percent', '(': '', ')': '', ',': '', ':': '', '-': '', '$': 'D', '.': '', '/': '', '=': '', '&': '', ' ': '_', '\"': ''}\n","\n","\n","\n","    for i, attribute in enumerate(col):\n","        original = attribute\n","        for key in replace_dict:\n","            attribute = attribute.replace(key, replace_dict[key])\n","        col[i] = attribute\n","        original_dict[attribute] = original\n","    return df, col, original_dict\n","\n","\n","\n","def null_hypothesis_rejected(fvalue, f_pvalue):\n","    return fvalue > 1 and f_pvalue < 0.05\n","\n","\n","def compute_formula(target_attribute, other_attributes):\n","    formula = str(target_attribute) + \" ~ \"\n","\n","    for i, attribute in enumerate(other_attributes):\n","        # print(attribute)\n","        if attribute != target_attribute:\n","            formula += str(other_attributes[i]) + \" + \"\n","\n","    formula = formula[:-3]\n","    # print(formula)\n","    return formula\n","\n","\n","def compute_dependency(dataframe, target_attribute):\n","    fvalue, f_pvalue = 0, 0\n","\n","    #while not null_hypothesis_rejected(fvalue, f_pvalue):\n","    #for i in range(30):\n","    col = list(dataframe.columns)\n","    formula = compute_formula(target_attribute, col)\n","    if target_attribute in col: \n","        col.remove(target_attribute)\n","    \n","    try:\n","        model = smf.ols(formula = formula, data = dataframe)\n","\n","    except:\n","        # print('formula: ', formula)\n","        # print('target: ', target_attribute)\n","        # print('dataframe: ', dataframe)\n","        return 0, 0, 0, []\n","\n","        \n","    result = model.fit()\n","    fvalue = result.fvalue\n","    f_pvalue = result.f_pvalue\n","    params = list(result.params)\n","    mapped_params = [(col[i], params[i]) for i in range(min(len(params), len(col)))]\n","    sorted_params = sorted(mapped_params, key = lambda x: abs(x[1]))\n","    least_imp_param = sorted_params[0][0]\n","    dataframe.drop(least_imp_param, inplace=True, axis=1)\n","\n","    if len(sorted_params) < 3:\n","        return fvalue, f_pvalue, len(sorted_params), sorted_params\n","\n","    # print(params)\n","\n","    return fvalue, f_pvalue, sorted_params # result\n","\n","\n","def remaping(stats, originals):\n","    # print(stats)\n","    for j, attribute in enumerate(stats[2]):\n","        stats[2][j] = (originals[stats[2][j][0]], stats[2][j][1])\n","    return stats\n","\n","\n","\n","############################################### Copy everything below this in this cell #####################################\n","\n","def sanitised(col):\n","    originals = {}\n","    replace_dict = {'%': 'percent', '(': '', ')': '', ',': '', ':': '', '-': '', '$': 'D', '.': '', '/': '', '=': '', '&': '', ' ': '_', '\"': ''}\n","\n","    for i, attribute in enumerate(col):\n","        original = attribute\n","        for key in replace_dict:\n","            attribute = attribute.replace(key, replace_dict[key])\n","        col[i] = attribute\n","        originals[attribute] = original\n","\n","        return col[0], col[1:], originals\n","\n","\n","############################################### Use This Function ########################################\n","def test_hypothesis(target_attribute, dependent_attributes, country):\n","    df, col, original_dict = data_sanitisation()\n","    # print(df.columns)\n","    # print(col)\n","    df.columns = col\n","    target_attribute, dependent_attributes, originals = sanitised([target_attribute] + dependent_attributes)\n","    \n","    # df.drop(columns = ['Country_Name', '_Country_Code', '_Year'], inplace = True, axis = 1)\n","    new_df = df.filter([target_attribute] + dependent_attributes, axis = 1)\n","    # print(new_df.columns)\n","    res = compute_dependency(new_df, target_attribute)\n","    ############### Code to group by country ##############\n","    # file_rdd = sc.parallelize(df.to_numpy())\n","\n","    # grouped_rdd = file_rdd.map(lambda x: (x[0], x[3:])).groupByKey().mapValues(list)\n","\n","    # df_rdd = grouped_rdd.map(lambda x: (x[0], pd.DataFrame(x[1], columns = col[3:]) ))       # Grouping Country wise and dropping country code and time fields\n","    \n","    # model_rdd = df_rdd.map(lambda x: (x[0], compute_dependency(x[1], target_attribute))) #.map(lambda x: (x[0], x[1].params))\n","\n","    \n","    # # summary_rdd = model_rdd.map(lambda x: (x[0], x[1].fvalue, x[1].f_pvalue))\n","    # stats = model_rdd.collectAsMap()\n","\n","    # res = stats[country]\n","\n","    new_stats = remaping(res, original_dict)\n","    # print(model_rdd.collect())\n","    return new_stats\n","\n","\n","\n"],"metadata":{"id":"YEMXtTinBZuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install statsmodels"],"metadata":{"id":"kxhma6y-UU0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aimuUWJWSFDF","executionInfo":{"status":"ok","timestamp":1652427368051,"user_tz":240,"elapsed":214,"user":{"displayName":"Saurabh Parekh","userId":"04271885658909513257"}},"outputId":"65be20fb-4be8-4945-a5a9-4237b0cee1d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Month\n","1901-01-01    266.0\n","1901-02-01    145.9\n","1901-03-01    183.1\n","1901-04-01    119.3\n","1901-05-01    180.3\n","1901-06-01    168.5\n","1901-07-01    231.8\n","1901-08-01    224.5\n","1901-09-01    192.8\n","1901-10-01    122.9\n","1901-11-01    336.5\n","1901-12-01    185.9\n","1902-01-01    194.3\n","1902-02-01    149.5\n","1902-03-01    210.1\n","1902-04-01    273.3\n","1902-05-01    191.4\n","1902-06-01    287.0\n","1902-07-01    226.0\n","1902-08-01    303.6\n","1902-09-01    289.9\n","1902-10-01    421.6\n","1902-11-01    264.5\n","1902-12-01    342.3\n","1903-01-01    339.7\n","1903-02-01    440.4\n","1903-03-01    315.9\n","1903-04-01    439.3\n","1903-05-01    401.3\n","1903-06-01    437.4\n","1903-07-01    575.5\n","1903-08-01    407.6\n","1903-09-01    682.0\n","1903-10-01    475.3\n","1903-11-01    581.3\n","1903-12-01    646.9\n","Name: Sales, dtype: float64\n","[266.  145.9 183.1 119.3 180.3 168.5 231.8 224.5 192.8 122.9 336.5 185.9\n"," 194.3 149.5 210.1 273.3 191.4 287.  226.  303.6 289.9 421.6 264.5 342.3\n"," 339.7 440.4 315.9 439.3 401.3 437.4 575.5 407.6 682.  475.3 581.3 646.9]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}],"source":["# evaluate an ARIMA model using a walk-forward validation\n","from pandas import read_csv\n","from pandas import datetime\n","from matplotlib import pyplot\n","from statsmodels.tsa.arima.model import ARIMA\n","from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","# load dataset\n","def parser(x):\n","\treturn datetime.strptime('190'+x, '%Y-%m')\n","series = read_csv('shampoo.csv', header=0, index_col=0, parse_dates=True, squeeze=True, date_parser=parser)\n","print(series)\n","series.index = series.index.to_period('M')\n","# split into train and test sets\n","X = series.values\n","print(X)\n","# size = int(len(X) * 0.66)\n","# train, test = X[0:size], X[size:len(X)]\n","# history = [x for x in train]\n","# predictions = list()\n","# # walk-forward validation\n","# for t in range(len(test)):\n","# \tmodel = ARIMA(history, order=(5,1,0))\n","# \tmodel_fit = model.fit()\n","# \toutput = model_fit.forecast()\n","# \tyhat = output[0]\n","# \tpredictions.append(yhat)\n","# \tobs = test[t]\n","# \thistory.append(obs)\n","# \tprint('predicted=%f, expected=%f' % (yhat, obs))\n","# # evaluate forecasts\n","# rmse = sqrt(mean_squared_error(test, predictions))\n","# print('Test RMSE: %.3f' % rmse)\n","# # plot forecasts against actual outcomes\n","# pyplot.plot(test)\n","# pyplot.plot(predictions, color='red')\n","# pyplot.show()"]},{"cell_type":"code","source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"JxL5M73MVbQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reading the CSV file\n","text = open(\"dfFltrd8May - dfFltrd8May.csv\", \"r\")\n","  \n","# join() method combines all contents of \n","# csvfile.csv and formed as a string\n","text = ''.join([i for i in text]) \n","  \n","# search and replace the contents\n","text = text.replace(\"Urban population growth (annual %)\", \"Urban_Population_Growth\") \n","text = text.replace(\"Urban population (% of total population)\", \"Urban_Population\") \n","text = text.replace(\"Access to electricity, urban (% of urban population)\", \"Access_to_electricity\") \n","  \n","# output.csv is the output file opened in write mode\n","x = open(\"output.csv\",\"w\")\n","  \n","# all the replaced text is written in the output.csv file\n","x.writelines(text)\n","x.close()"],"metadata":{"id":"6el5grrvcCal"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"output.csv\")\n","df = df.dropna()\n","# df = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n","# df = df[['Lottery', 'Literacy', 'Wealth', 'Region']].dropna()\n","print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zxKB5rPVoWx","executionInfo":{"status":"ok","timestamp":1652480012987,"user_tz":240,"elapsed":406,"user":{"displayName":"Saurabh Parekh","userId":"04271885658909513257"}},"outputId":"3460a2f5-97b7-4464-f344-74cc24ed0fe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Country Name', 'Country Code', 'Year', 'Forest area (% of land area)',\n","       'Urban_Population', 'Urban_Population_Growth', 'Access_to_electricity',\n","       'Renewable energy consumption (% of total final energy consumption)',\n","       'Individuals using the Internet (% of population)',\n","       'Adjusted savings: carbon dioxide damage (% of GNI)',\n","       'Adjusted savings: energy depletion (% of GNI)',\n","       'Adjusted savings: mineral depletion (% of GNI)',\n","       'Merchandise trade (% of GDP)',\n","       'Adjusted savings: natural resources depletion (% of GNI)',\n","       'Exports of goods and services (% of GDP)',\n","       'Imports of goods and services (% of GDP)', 'Trade (% of GDP)',\n","       'Forest rents (% of GDP)', 'Mineral rents (% of GDP)',\n","       'GDP (current US$)', 'GDP per capita, PPP (current international $)',\n","       'GNI (current US$)', 'Compulsory education, duration (years)',\n","       'Probability of dying among children ages 5-9 years (per 1,000)',\n","       'Probability of dying among adolescents ages 10-14 years (per 1,000)',\n","       'Probability of dying among adolescents ages 15-19 years (per 1,000)',\n","       'Probability of dying among youth ages 20-24 years (per 1,000)',\n","       'Number of infant deaths', 'International tourism, number of arrivals',\n","       'Net bilateral aid flows from DAC donors, United States (current US$)',\n","       'Net bilateral aid flows from DAC donors, Japan (current US$)',\n","       'Net bilateral aid flows from DAC donors, Germany (current US$)',\n","       'Net bilateral aid flows from DAC donors, United Kingdom (current US$)',\n","       'Net bilateral aid flows from DAC donors, Norway (current US$)',\n","       'Net bilateral aid flows from DAC donors, Total (current US$)',\n","       'Current health expenditure (% of GDP)',\n","       'Prevalence of undernourishment (% of population)',\n","       'International tourism, expenditures (% of total imports)',\n","       'Communications, computer, etc. (% of service imports, BoP)',\n","       'Foreign direct investment, net outflows (BoP, current US$)',\n","       'CO2 emissions (metric tons per capita)',\n","       'Cost of business start-up procedures (% of GNI per capita)',\n","       'Military expenditure (% of GDP)', 'Import value index (2000 = 100)',\n","       'Market capitalization of listed domestic companies (% of GDP)',\n","       'Listed domestic companies, total',\n","       'Energy intensity level of primary energy (MJ/$2011 PPP GDP)',\n","       'PM2.5 air pollution, population exposed to levels exceeding WHO guideline value (% of total)',\n","       'Research and development expenditure (% of GDP)',\n","       'Researchers in R&D (per million people)',\n","       'Automated teller machines (ATMs) (per 100,000 adults)',\n","       'Hospital beds (per 1,000 people)', 'Physicians (per 1,000 people)',\n","       'High-technology exports (current US$)',\n","       'New business density (new registrations per 1,000 people ages 15-64)',\n","       'Exports as a capacity to import (constant LCU)',\n","       'International tourism, number of departures'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# mod = smf.ols(formula='Lottery ~ Literacy + Wealth + Region', data=df)\n","col = df.columns\n","formula = \"{} ~ {} + {}\".format(col[5], col[4], col[6])\n","mod = smf.ols(formula=formula, data=df)\n","res = mod.fit()"],"metadata":{"id":"A-Xz8VAwWWwO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(res.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TU4-qT2RWcak","executionInfo":{"status":"ok","timestamp":1652480030806,"user_tz":240,"elapsed":222,"user":{"displayName":"Saurabh Parekh","userId":"04271885658909513257"}},"outputId":"dd80e1a2-3297-4944-de26-f4cbdbf3c7c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                               OLS Regression Results                              \n","===================================================================================\n","Dep. Variable:     Urban_Population_Growth   R-squared:                       0.107\n","Model:                                 OLS   Adj. R-squared:                  0.026\n","Method:                      Least Squares   F-statistic:                     1.321\n","Date:                     Fri, 13 May 2022   Prob (F-statistic):              0.287\n","Time:                             22:13:50   Log-Likelihood:                -21.415\n","No. Observations:                       25   AIC:                             48.83\n","Df Residuals:                           22   BIC:                             52.49\n","Df Model:                                2                                         \n","Covariance Type:                 nonrobust                                         \n","=========================================================================================\n","                            coef    std err          t      P>|t|      [0.025      0.975]\n","-----------------------------------------------------------------------------------------\n","Intercept                26.3999     22.955      1.150      0.262     -21.206      74.005\n","Urban_Population         -0.0068      0.009     -0.724      0.477      -0.026       0.013\n","Access_to_electricity    -0.2432      0.233     -1.045      0.307      -0.726       0.240\n","==============================================================================\n","Omnibus:                       13.082   Durbin-Watson:                   2.381\n","Prob(Omnibus):                  0.001   Jarque-Bera (JB):               16.807\n","Skew:                          -1.018   Prob(JB):                     0.000224\n","Kurtosis:                       6.463   Cond. No.                     2.31e+04\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 2.31e+04. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n"]}]},{"cell_type":"code","source":["print(res.params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kcw83ZyhEb_","executionInfo":{"status":"ok","timestamp":1652480572260,"user_tz":240,"elapsed":193,"user":{"displayName":"Saurabh Parekh","userId":"04271885658909513257"}},"outputId":"48ab67dd-79ee-41d5-ce1c-3aef0026ef95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Intercept                26.399860\n","Urban_Population         -0.006848\n","Access_to_electricity    -0.243215\n","dtype: float64\n"]}]}]}